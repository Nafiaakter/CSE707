Title: Apache Spark: An integrated motor for Big Data Processing
Author: Matai Zahria, Reynold Shin, Patrick Wandel, Tathagata Das, Michael Brammst, et al.
Source: Communication of ACM, 2016


Summary:


This article introduces Apache Sparks, an open source distributed data processing designed to process large data quickly and efficiently. Spark improves traditional Hadoop Mapreduce, provides help with memory calculations and various workloads such as batch treatment, interactive query, streaming and machine learning.


Authors explain the nuclear abstraction of the spark, called the resolution distributed dataset (RDD), which enables the fault tolerant, parallel operation on a large dataset. Unlike Mapreduce, Sparks between data in memory has often improved the performance for the relapse algorithm used in text mining (eg TF -DF calculation, grouping, professional modeling).


Paper exposes modular components of sparks, including:


Spark SQL for structured data


Mllib for scalable machine learning


Graffes for graph treatment


Spark streaming for real -time data


The author shows that Spark outperform Hadop increases 100 times faster in memory and quickly on a record, making it a very effective solution for big data text analysis.


This article is important for my project because Apache Spark is the basis for most modern distributed text equipment pipes. The recycling machine makes the ideal to handle carpora in large -scale text in the atmosphere, distributed support for learning and effective treatment in memory.


Reference:


Zaharia, M., Xin, R., Wendell, P., Das, T., Armbrust, M., Dave, A., Meng, X., Rosen, J., Venkataraman, S., Franklin, M. J., Ghodsi, A., Gonzalez, J. E., Shenker, S., & Stoica, I. (2016). Apache Spark: A unified engine for big data processing. Communications of the ACM, 59(11), 56–65. https://doi.org/10.1145/2934664